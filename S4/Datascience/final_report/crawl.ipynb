{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa360c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from cgitb import html\n",
    "import pandas as pd \n",
    "import re\n",
    "import time\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "# 控制選單\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb6c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_stock_tw_v1(_ticker, _year):\n",
    "    url = r'https://www.twse.com.tw/zh/page/trading/exchange/STOCK_DAY.html' \n",
    "    s = Service(r'C:\\SDK\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "    browser = webdriver.Chrome(service=s) \n",
    "    browser.maximize_window() \n",
    "    browser.get(url) \n",
    "    sleep(1)\n",
    "\n",
    "    browser.find_element(by=By.XPATH, value='//*[@id=\"main-form\"]/div/div/form/input').send_keys(str(_ticker))\n",
    "\n",
    "    Select(browser.find_element(by=By.NAME, value='yy')).select_by_value(_year)\n",
    "\n",
    "    browser.find_element(by=By.XPATH, value='//*[@id=\"main-form\"]/div/div/form/a[2]').click()\n",
    "\n",
    "    for i in range(12):\n",
    "        # 選取表單_設定月分\n",
    "        Select(browser.find_element(by=By.NAME, value='mm')).select_by_index(i)\n",
    "        # 點擊查詢按鈕\n",
    "        browser.find_element(by=By.XPATH, value='//*[@id=\"main-form\"]/div/div/form/a[2]').click()\n",
    "        # 點擊下載按鈕\n",
    "        csv = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"csv\")))\n",
    "        time.sleep(5)\n",
    "        csv.click()\n",
    "\n",
    "    time.sleep(1)\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718d0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_stock_tw(_ticker, _year):\n",
    "\n",
    "    s = Service(r'C:\\SDK\\chromedriver_win32\\chromedriver.exe')\n",
    "    browser = webdriver.Chrome(service=s) \n",
    "    browser.maximize_window() \n",
    "\n",
    "    for i in range(1, 13):\n",
    "        url = 'https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=csv&date={}{:02}01&stockNo={}'.format(_year, i, _ticker)\n",
    "        browser.get(url) \n",
    "        sleep(5)\n",
    "\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72a2188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "stock = 3169\n",
    "# 判定 os_test 資料夾是否存在\n",
    "if not os.path.isdir('data_unmerged'): \n",
    "    os.mkdir('data_unmerged')\n",
    "# 取得當前路徑\n",
    "destination = os.getcwd() + '\\\\data_unmerged' \n",
    "\n",
    "source = os.listdir(r\"C:\\Users\\User\\Downloads\")\n",
    "#過濾其他檔案，只保留csv檔\n",
    "source = [line for line in source if str(stock) in line] \n",
    "print(source)\n",
    "\n",
    "# 移動下載檔案進入資料夾\n",
    "for s in source:\n",
    "    path = os.path.join(r\"C:\\Users\\User\\Downloads\", s)\n",
    "    shutil.move(path, os.path.join(destination, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686a0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_stock_tw(_ticker):\n",
    "    # 判定 os_test 資料夾是否存在\n",
    "    if not os.path.isdir('data_unmerged'): \n",
    "        os.mkdir('data_unmerged')\n",
    "    # 取得當前路徑\n",
    "    destination = os.getcwd() + '\\\\data_unmerged' \n",
    "\n",
    "    source = os.listdir(r\"C:\\Users\\User\\Downloads\")\n",
    "    #過濾其他檔案，只保留csv檔\n",
    "    source = [line for line in source if str(_ticker) in line] \n",
    "    print(source)\n",
    "\n",
    "    # 移動下載檔案進入資料夾\n",
    "    for s in source:\n",
    "        path = os.path.join(r\"C:\\Users\\User\\Downloads\", s)\n",
    "        shutil.move(path, os.path.join(destination, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ad1888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock = 3169\n",
    "path = os.getcwd() + '\\\\data_unmerged\\\\'\n",
    "source = os.listdir(path)\n",
    "source = [line for line in source if str(stock) in line]\n",
    "\n",
    "res = pd.DataFrame(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "\n",
    "for s in source:\n",
    "    print(s)\n",
    "    df = pd.read_csv(destination + s, encoding='Big5', skiprows=1)\n",
    "    df = df.iloc[:-4, :7]\n",
    "    df.columns = ['Date', 'Volume', 'b', 'Open', 'High', 'Low', 'Close']\n",
    "    df.drop('b', axis = 1, inplace = True) \n",
    "    df = df.reindex(columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    df.loc[:, 'Date'] = df.loc[:, 'Date'].str.split('/').apply(lambda x:(str(int(x[0]) + 1911)) + '/' + x[1].removeprefix('0') + '/' + x[2].removeprefix('0'))\n",
    "    df.loc[:, 'Volume'] = df.loc[:, 'Volume'].str.replace(',', '').astype(int) // 1000\n",
    "    res = res.append(df, ignore_index = True)\n",
    "\n",
    "res['Date'] = pd.to_datetime(res['Date'])\n",
    "res.sort_values(by='Date', ascending=False)\n",
    "\n",
    "# 判定 os_test 資料夾是否存在\n",
    "if not os.path.isdir('data'): \n",
    "    os.mkdir('data')\n",
    "\n",
    "res.to_csv(os.getcwd() + '\\\\data\\\\filename.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0bc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stock_tw(_ticker):\n",
    "    \n",
    "    # 判定 data 資料夾是否存在\n",
    "    if not os.path.isdir('data'): \n",
    "        os.mkdir('data')\n",
    "    \n",
    "    path = os.getcwd() + '\\\\data_unmerged\\\\'\n",
    "    source = os.listdir(path)\n",
    "    source = [line for line in source if str(_ticker) in line]\n",
    "    \n",
    "    if os.path.isfile(r'./data/{}.csv'.format(str(_ticker))): \n",
    "        res = pd.read_csv(os.getcwd() + '\\\\data\\{}.csv'.format(str(_ticker)))\n",
    "    else:\n",
    "        res = pd.DataFrame(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    \n",
    "    for s in source:\n",
    "        print(s)\n",
    "        df = pd.read_csv(destination + s, encoding='Big5', skiprows=1)\n",
    "        df = df.iloc[:-4, :7]\n",
    "        df.columns = ['Date', 'Volume', 'b', 'Open', 'High', 'Low', 'Close']\n",
    "        df.drop('b', axis = 1, inplace = True) \n",
    "        df = df.reindex(columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "        df.loc[:, 'Date'] = df.loc[:, 'Date'].str.split('/').apply(lambda x:(str(int(x[0]) + 1911)) + '/' + x[1].removeprefix('0') + '/' + x[2].removeprefix('0'))\n",
    "        df.loc[:, 'Volume'] = df.loc[:, 'Volume'].str.replace(',', '').astype(int) // 1000\n",
    "        res = res.append(df, ignore_index = True)\n",
    "    \n",
    "    \n",
    "    res['Date'] = pd.to_datetime(res['Date'])\n",
    "    res = res.drop_duplicates(subset='Date', keep='first')\n",
    "    res.sort_values(by='Date', ascending=True, inplace=True)\n",
    "    \n",
    "    res.to_csv(os.getcwd() + '\\\\data\\\\' + str(_ticker) + '.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "57db88a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查詢股票代碼 -> 2409\n",
      "查詢年份 -> 2019\n",
      "['STOCK_DAY_2409_201901.csv', 'STOCK_DAY_2409_201902.csv', 'STOCK_DAY_2409_201903.csv', 'STOCK_DAY_2409_201904.csv', 'STOCK_DAY_2409_201905.csv', 'STOCK_DAY_2409_201906.csv', 'STOCK_DAY_2409_201907.csv', 'STOCK_DAY_2409_201908.csv', 'STOCK_DAY_2409_201909.csv', 'STOCK_DAY_2409_201910.csv', 'STOCK_DAY_2409_201911.csv', 'STOCK_DAY_2409_201912.csv']\n",
      "           Date   Open   High    Low  Close  Volume\n",
      "0    2020-01-02  10.15  10.20  10.10  10.15   34118\n",
      "1    2020-01-03  10.20  10.25   9.89  10.05   68859\n",
      "2    2020-01-06  10.10  10.20   9.89   9.96   67039\n",
      "3    2020-01-07  10.05  10.20   9.98  10.05   66052\n",
      "4    2020-01-08   9.96  10.35   9.85  10.35  145245\n",
      "..          ...    ...    ...    ...    ...     ...\n",
      "484  2021-12-24  22.45  22.60  22.25  22.45   49699\n",
      "485  2021-12-27  22.50  23.00  22.50  22.70   72941\n",
      "486  2021-12-28  22.90  23.00  22.60  22.65   51370\n",
      "487  2021-12-29  22.70  22.85  22.50  22.75   39207\n",
      "488  2021-12-30  22.80  23.15  22.75  22.90   84382\n",
      "\n",
      "[489 rows x 6 columns]\n",
      "STOCK_DAY_2409_201901.csv\n",
      "STOCK_DAY_2409_201902.csv\n",
      "STOCK_DAY_2409_201903.csv\n",
      "STOCK_DAY_2409_201904.csv\n",
      "STOCK_DAY_2409_201905.csv\n",
      "STOCK_DAY_2409_201906.csv\n",
      "STOCK_DAY_2409_201907.csv\n",
      "STOCK_DAY_2409_201908.csv\n",
      "STOCK_DAY_2409_201909.csv\n",
      "STOCK_DAY_2409_201910.csv\n",
      "STOCK_DAY_2409_201911.csv\n",
      "STOCK_DAY_2409_201912.csv\n",
      "STOCK_DAY_2409_202001.csv\n",
      "STOCK_DAY_2409_202002.csv\n",
      "STOCK_DAY_2409_202003.csv\n",
      "STOCK_DAY_2409_202004.csv\n",
      "STOCK_DAY_2409_202005.csv\n",
      "STOCK_DAY_2409_202006.csv\n",
      "STOCK_DAY_2409_202007.csv\n",
      "STOCK_DAY_2409_202008.csv\n",
      "STOCK_DAY_2409_202009.csv\n",
      "STOCK_DAY_2409_202010.csv\n",
      "STOCK_DAY_2409_202011.csv\n",
      "STOCK_DAY_2409_202012.csv\n",
      "STOCK_DAY_2409_202101.csv\n",
      "STOCK_DAY_2409_202102.csv\n",
      "STOCK_DAY_2409_202103.csv\n",
      "STOCK_DAY_2409_202104.csv\n",
      "STOCK_DAY_2409_202105.csv\n",
      "STOCK_DAY_2409_202106.csv\n",
      "STOCK_DAY_2409_202107.csv\n",
      "STOCK_DAY_2409_202108.csv\n",
      "STOCK_DAY_2409_202109.csv\n",
      "STOCK_DAY_2409_202110.csv\n",
      "STOCK_DAY_2409_202111.csv\n",
      "STOCK_DAY_2409_202112.csv\n"
     ]
    }
   ],
   "source": [
    "stock = input(\"查詢股票代碼 -> \")\n",
    "year = input(\"查詢年份 -> \")\n",
    "\n",
    "crawl_stock_tw_v1(stock, year)\n",
    "move_stock_tw(stock)\n",
    "merge_stock_tw(stock)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
